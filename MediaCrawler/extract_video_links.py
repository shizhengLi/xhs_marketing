#!/usr/bin/env python3
"""
æå–å°çº¢ä¹¦æ•°æ®ä¸­çš„è§†é¢‘é“¾æ¥
"""
import json
from pathlib import Path
from collections import defaultdict

def extract_video_links():
    """æå–æ‰€æœ‰è§†é¢‘é“¾æ¥"""

    json_dir = Path("/Users/lishizheng/Desktop/Code/xhs_marketing/MediaCrawler/data/xhs/json")
    content_files = list(json_dir.glob("search_contents_*.json"))

    print(f"=== å°çº¢ä¹¦è§†é¢‘é“¾æ¥æå– ===\n")

    all_video_data = []

    for file_path in sorted(content_files):
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {file_path.name}")

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            for note in data:
                video_url = note.get('video_url', '').strip()
                if video_url:
                    video_info = {
                        'title': note.get('title', ''),
                        'note_id': note.get('note_id', ''),
                        'video_url': video_url,
                        'note_url': note.get('note_url', ''),
                        'liked_count': note.get('liked_count', ''),
                        'author': note.get('nickname', ''),
                        'source_keyword': note.get('source_keyword', ''),
                        'file_source': file_path.name
                    }
                    all_video_data.append(video_info)

        except Exception as e:
            print(f"   âŒ é”™è¯¯: {str(e)}")

    # ä¿å­˜è§†é¢‘é“¾æ¥åˆ°æ–‡ä»¶
    output_file = json_dir.parent / "video_links_extracted.json"

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_video_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æˆåŠŸæå– {len(all_video_data)} ä¸ªè§†é¢‘é“¾æ¥")
    print(f"ğŸ“ ä¿å­˜åˆ°: {output_file}")

    # æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š è§†é¢‘é“¾æ¥ç»Ÿè®¡:")

    # æŒ‰å…³é”®è¯ç»Ÿè®¡
    keyword_stats = defaultdict(int)
    for video in all_video_data:
        keyword = video.get('source_keyword', 'unknown')
        keyword_stats[keyword] += 1

    print(f"\nğŸ¯ æŒ‰å…³é”®è¯åˆ†ç±»:")
    for keyword, count in sorted(keyword_stats.items(), key=lambda x: x[1], reverse=True):
        print(f"   {keyword}: {count} ä¸ªè§†é¢‘")

    # æ˜¾ç¤ºå‰5ä¸ªè§†é¢‘é“¾æ¥ç¤ºä¾‹
    print(f"\nğŸ”— è§†é¢‘é“¾æ¥ç¤ºä¾‹ (å‰5ä¸ª):")
    for i, video in enumerate(all_video_data[:5], 1):
        print(f"\n{i}. {video['title'][:40]}...")
        print(f"   ä½œè€…: {video['author']}")
        print(f"   ç‚¹èµ: {video['liked_count']}")
        print(f"   å…³é”®è¯: {video['source_keyword']}")
        print(f"   è§†é¢‘: {video['video_url'][:80]}...")

if __name__ == "__main__":
    extract_video_links()