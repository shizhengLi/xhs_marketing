#!/usr/bin/env python3
"""
ç¯å¢ƒå˜é‡æ£€æŸ¥è„šæœ¬
éªŒè¯OpenAI APIé…ç½®æ˜¯å¦æ­£ç¡®
"""
import os
import sys

def check_env_vars():
    """æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®"""
    print("ğŸ” æ£€æŸ¥OpenAI APIç¯å¢ƒå˜é‡é…ç½®...")
    print("-" * 50)

    # å°è¯•åŠ è½½.envæ–‡ä»¶
    try:
        from dotenv import load_dotenv
        load_dotenv()
        print("âœ… python-dotenv å·²å®‰è£…ï¼Œ.envæ–‡ä»¶å·²åŠ è½½")
    except ImportError:
        print("âš ï¸  python-dotenv æœªå®‰è£…ï¼Œä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡")

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv("OPENAI_API_KEY")
    api_base = os.getenv("OPENAI_API_BASE")
    ai_model = os.getenv("AI_MODEL", "gpt-3.5-turbo")

    # æ£€æŸ¥ç»“æœ
    if api_key:
        print(f"âœ… OPENAI_API_KEY: {api_key[:10]}...{api_key[-4:]}")
    else:
        print("âŒ OPENAI_API_KEY: æœªè®¾ç½®")
        print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®: OPENAI_API_KEY=your-key-here")

    if api_base:
        print(f"âœ… OPENAI_API_BASE: {api_base}")
    else:
        print("âŒ OPENAI_API_BASE: æœªè®¾ç½®")
        print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®: OPENAI_API_BASE=https://api.openai.com/v1")

    print(f"âœ… AI_MODEL: {ai_model}")

    # éªŒè¯é…ç½®
    if api_key and api_base:
        print("\nğŸ‰ ç¯å¢ƒå˜é‡é…ç½®å®Œæ•´ï¼")
        return True
    else:
        print("\nâŒ ç¯å¢ƒå˜é‡é…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é…ç½®")
        return False

def test_openai_connection():
    """æµ‹è¯•OpenAIè¿æ¥"""
    print("\nğŸ” æµ‹è¯•OpenAI APIè¿æ¥...")
    print("-" * 50)

    try:
        from openai import OpenAI
        import os

        # ç¡®ä¿åŠ è½½äº†ç¯å¢ƒå˜é‡
        try:
            from dotenv import load_dotenv
            load_dotenv()
        except ImportError:
            pass

        api_key = os.getenv("OPENAI_API_KEY")
        api_base = os.getenv("OPENAI_API_BASE")

        if not api_key or not api_base:
            print("âŒ æ— æ³•æµ‹è¯•è¿æ¥ï¼šç¯å¢ƒå˜é‡é…ç½®ä¸å®Œæ•´")
            return False

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = OpenAI(api_key=api_key, base_url=api_base)
        print("âœ… OpenAIå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•ç®€å•è°ƒç”¨
        print("ğŸ§ª æµ‹è¯•APIè°ƒç”¨...")
        response = client.chat.completions.create(
            model=os.getenv("AI_MODEL", "gpt-3.5-turbo"),
            messages=[{"role": "user", "content": "Hi"}],
            max_tokens=10
        )

        if response.choices:
            print("âœ… APIè°ƒç”¨æˆåŠŸ")
            return True
        else:
            print("âŒ APIè°ƒç”¨å¤±è´¥ï¼šæœªè¿”å›æœ‰æ•ˆå“åº”")
            return False

    except Exception as e:
        print(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
        return False

def test_llm_service():
    """æµ‹è¯•LLMæœåŠ¡"""
    print("\nğŸ” æµ‹è¯•LLMæœåŠ¡...")
    print("-" * 50)

    try:
        from app.services.llm_service import expand_keywords_with_llm
        print("âœ… LLMæœåŠ¡å¯¼å…¥æˆåŠŸ")

        # æµ‹è¯•å…³é”®è¯æ‰©å±•
        print("ğŸ§ª æµ‹è¯•å…³é”®è¯æ‰©å±•...")
        result = expand_keywords_with_llm("åŒè‚©åŒ…", count=2)
        print(f"âœ… å…³é”®è¯æ‰©å±•æˆåŠŸ: {result}")
        return True

    except Exception as e:
        print(f"âŒ LLMæœåŠ¡æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

if __name__ == "__main__":
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    env_ok = check_env_vars()

    if env_ok:
        # å¦‚æœç¯å¢ƒå˜é‡é…ç½®æ­£ç¡®ï¼Œæµ‹è¯•è¿æ¥
        connection_ok = test_openai_connection()

        if connection_ok:
            # å¦‚æœè¿æ¥æˆåŠŸï¼Œæµ‹è¯•LLMæœåŠ¡
            test_llm_service()

    print("\n" + "=" * 50)
    print("æ£€æŸ¥å®Œæˆï¼")
    print("=" * 50)